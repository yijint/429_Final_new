{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2154c6cd-1a03-44cb-90d7-e8d5caa8ac42",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ensemble model\n",
    "The ensemble combines five models:\n",
    "1. best L1 value\n",
    "2. best L2 value\n",
    "3. augmented \n",
    "4. best dropout value \n",
    "5. best model architecture (TBD)\n",
    "\n",
    "This notebook performs and saves the ensemble predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf239be2-e01a-4b3a-869b-f4d554146b0b",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed55ba98-da3b-4d05-87f1-b185f5cb4071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy_ml.neural_nets.losses import CrossEntropy as np_CrossEntropy\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ca1dda-bdf6-4f2b-9c5a-28044a2348ce",
   "metadata": {},
   "source": [
    "Load logits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "110ed83f-2108-45ba-9d7e-cb8103e44e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = \"/home/jt9744/COS429/429_Final_new/ensemble_models/\"\n",
    "L1_name = \"30epochs_l1_lr_0.1_ld_0.0001\"\n",
    "L2_name = \"30epochs_l2_lr_0.1_wd_1e-11\"\n",
    "augment_name = \"60epochs_l2_lr_0.1_wd_1e-07_augment\"\n",
    "dropout_name = \"30epochs_l1_lr_0.1_ld_1e-07_dropout_06\" \n",
    "architecture_name = \"30epochs_l2_lr_0.1_wd_1e-07_1lesslayer\" \n",
    "baseline_name = \"30epochs_l2_lr_0.1_wd_1e-07\"\n",
    "num_classes = 11 # from previous knowledge, e.g. check preprocess.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd737fb1-326a-4a48-a2e7-db8784fea9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_logits = np.loadtxt(models_path+'LOGITS_'+L1_name)\n",
    "L2_logits = np.loadtxt(models_path+'LOGITS_'+L2_name)\n",
    "aug_logits = np.loadtxt(models_path+'LOGITS_'+augment_name)\n",
    "drop_logits = np.loadtxt(models_path+'LOGITS_'+dropout_name)\n",
    "arch_logits = np.loadtxt(models_path+'LOGITS_'+architecture_name)\n",
    "baseline_logits = np.loadtxt(models_path+'LOGITS_'+baseline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5240e368-8218-4ff4-b905-8ec42c1eff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_preds = L1_logits.argmax(axis=1) # convert logits into predictions for evaluating accuracy\n",
    "np.savetxt(models_path+\"PREDS_L1\", L1_preds) # save predictions\n",
    "\n",
    "L2_preds = L2_logits.argmax(axis=1) # convert logits into predictions for evaluating accuracy\n",
    "np.savetxt(models_path+\"PREDS_L2\", L2_preds) # save predictions\n",
    "\n",
    "aug_preds = aug_logits.argmax(axis=1) # convert logits into predictions for evaluating accuracy\n",
    "np.savetxt(models_path+\"PREDS_aug\", aug_preds) # save predictions\n",
    "\n",
    "drop_preds = drop_logits.argmax(axis=1) # convert logits into predictions for evaluating accuracy\n",
    "np.savetxt(models_path+\"PREDS_drop\", drop_preds) # save predictions\n",
    "\n",
    "arch_preds = arch_logits.argmax(axis=1) # convert logits into predictions for evaluating accuracy\n",
    "np.savetxt(models_path+\"PREDS_arch\", arch_preds) # save predictions\n",
    "\n",
    "baseline_preds = baseline_logits.argmax(axis=1)\n",
    "np.savetxt(models_path+\"PREDS_baseline\", baseline_preds) # save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "955565df-9825-4108-aa6c-6905a9ea0a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = np.loadtxt(models_path+'TRUTH_'+L1_name).astype(np.int8) # all ground truths are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658b075e-5f49-40ad-9522-a8447770d8e8",
   "metadata": {},
   "source": [
    "Function to evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0888a41-bfd9-4d41-8a61-65af834dbd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns accuracy, f1 score, average f1, and confusion matrix for the data\n",
    "def eval_metrics(ground_truth, predictions, num_classes):\n",
    "\n",
    "    # dictionary containing the accuracy, precision, f1, avg f1, and confusion matrix for the data\n",
    "    f1 = f1_score(y_true=ground_truth, y_pred=predictions, labels=np.arange(num_classes), average=None)\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_true=ground_truth, y_pred=predictions),\n",
    "        \"f1\": f1,\n",
    "        \"average f1\": np.mean(f1),\n",
    "        \"confusion matrix\": confusion_matrix(y_true=ground_truth, y_pred=predictions, labels=np.arange(num_classes)),\n",
    "        \"precision\": precision_score(y_true=ground_truth, y_pred=predictions, labels=np.arange(num_classes), average=None)\n",
    "        }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab280820-b4c7-4a60-818a-a594e4b0f10c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ade97ca-d69b-4ee0-9054-bc7adb5e98fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = [L1_logits, L2_logits, aug_logits, drop_logits, arch_logits]\n",
    "logits = np.array([x for x in logits if x is not None]) # remove non-existing logits while waiting for them to train\n",
    "ensemble_logits = np.mean(logits, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ded95d50-680a-45c4-8ba9-dd2f92786f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_preds = ensemble_logits.argmax(axis=1) # convert logits into predictions for evaluating accuracy\n",
    "np.savetxt(models_path+\"PREDS_ensemble\", ensemble_preds) # save ensemble predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cos429",
   "language": "python",
   "name": "cos429"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
