# Animal Action Recognition with Pytorch i3d: Reducing Overfitting using Video Data Augmentation, Dropout, and Regularization
COS429 Final Project 

The code is structured in the following way:
Dataset:
1. preprocess.py and preprocess.ipynb contain the code for filtering the Animal Kingdom dataset for single-label classes with more than 100 videos

Model:
1. pytorch_i3d.py contains the code for constructing the baseline model (code adapted from https://github.com/piergiaj/pytorch-i3d)
2. rgb_imagenet.pt contains the pre-trained model
3. baseline_architecture.ipynb shows the layers in the baseline model 

Training:
1. train.py and train.ipynb contain the code for training the model 
2. train_job.slurm contains the script for scheduling a job for training 

Data augmentation:
1. vidaug.py contains the code for video augmentation, it is imported during training (code adapted from https://github.com/okankop/vidaug)

Reducing model complexity:
1. pytorch_i3d_1lesslayer.py contains the code for constructing the model with reduced complexity (code adapted from https://github.com/piergiaj/pytorch-i3d)

Predictions and model evaluation:
1. extract_logits.ipynb and extract_preds.ipynb contain the code for extracting the logits and predictions generated by a saved model on the validation set
2. evaluate.ipynb contains the code for visualizing the models' performance 
4. plotting.ipynb contains the code for visualizing the changes in cross-entropy loss, accuracy, and precision during training
